{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee29c092-0a8a-4475-84f2-8e0efc865185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install and Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1661ee07-1821-4954-8f82-a595facd2539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install google-api-python-client google-auth gspread openpyxl pyxirr\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a22a7b4-d9b5-47f9-9713-cd0f7ce72c01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Imports and Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a172cba3-493b-472a-bc0f-a787a8eb348a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "import gspread\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "SCOPES = [\n",
    "    'https://www.googleapis.com/auth/spreadsheets',\n",
    "    'https://www.googleapis.com/auth/drive'\n",
    "]\n",
    "KEY_FILE_PATH = '/Volumes/finance/raw/keys/databricks-drive-f6879bbdbe1c.json' \n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    KEY_FILE_PATH, scopes=SCOPES)\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "gc = gspread.authorize(creds)\n",
    "sheet_service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from pyxirr import xirr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ae8b0bf-ea58-4b38-a888-c7264a9034c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Fetch Screener Data ~ 60 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6864f0c-13b0-486e-bb6d-5140e85f0468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Screener():\n",
    "  def __init__(self):\n",
    "    self.base_url = 'https://www.screener.in'\n",
    "    self.industry_to_url = {}\n",
    "    self.stock_to_data = {}\n",
    "    self.epoch_time = time.time()\n",
    "    self.stock = None\n",
    "\n",
    "  def get_industry_to_url(self):\n",
    "    soup = BeautifulSoup(requests.get(self.base_url+'/market').text,'html.parser')\n",
    "    for ele in soup.find_all('a', href=lambda href: href and href.startswith('/market/')):\n",
    "      self.industry_to_url[ele.text] = self.base_url + ele['href']\n",
    "\n",
    "  def get_price_and_ratios(self):\n",
    "    for ele in self.stock_to_data[self.stock]['Soup'].find_all('span',{'class':'name'}):\n",
    "      if ele.text.strip() == 'Current Price':\n",
    "        self.stock_to_data[self.stock]['LTP'] = float(ele.find_next('span',{'class':'number'}).text.replace(',',''))\n",
    "      elif ele.text.strip() == 'High / Low':\n",
    "        self.stock_to_data[self.stock]['52W H'] = float(ele.find_all_next('span',{'class':'number'})[0].text.replace(',',''))\n",
    "        self.stock_to_data[self.stock]['52W L'] = float(ele.find_all_next('span',{'class':'number'})[1].text.replace(',',''))\n",
    "      elif ele.text.strip() == 'Stock P/E':\n",
    "        self.stock_to_data[self.stock]['PE'] = float(ele.find_next('span',{'class':'number'}).text.replace(',','')) if ele.find_next('span',{'class':'number'}).text.replace(',','')!='' else 0\n",
    "\n",
    "  def get_quarterly_results(self):\n",
    "    section = self.stock_to_data[self.stock]['Soup'].find('section',{'id':'quarters'})\n",
    "    if section:\n",
    "      self.stock_to_data[self.stock]['Reported_Upto'] = section.find('table',{'class':'data-table responsive-text-nowrap'}).find('thead').find_all('th')[-1].text.strip()\n",
    "      if section.find('span',{'class':'badge'}):\n",
    "        self.stock_to_data[self.stock]['Upcoming_Date'] = section.find('span',{'class':'badge'}).find('strong').text\n",
    "\n",
    "  def get_profit_loss(self):\n",
    "    section = self.stock_to_data[self.stock]['Soup'].find('section',{'id':'profit-loss'})\n",
    "    if section:\n",
    "      for row in section.find('table',{'class':'data-table responsive-text-nowrap'}).find_all('tr'):\n",
    "        if not self.stock_to_data[self.stock]['Reported_Upto']:\n",
    "          self.stock_to_data[self.stock]['Reported_Upto'] = row.find_all('th')[-1].text.strip()\n",
    "        button = row.find('button')\n",
    "        if button:\n",
    "          txt = button['onclick'].strip()\n",
    "          type = txt[txt.find(\"('\")+2:txt.find(\"',\")]\n",
    "        else:\n",
    "          type = row.find('td').text.strip() if row.find('td') else None\n",
    "        data = [float(col.text.strip().replace(',','').replace('%',''))\n",
    "          for col in row.find_all('td')[1:] if col.text.strip()]\n",
    "        if type in ['Sales','Revenue'] and len(data)>1:\n",
    "          self.stock_to_data[self.stock]['Sales_TTM'] = data[-1]\n",
    "        elif type in ['Net Profit'] and len(data)>1:\n",
    "          self.stock_to_data[self.stock]['Profit_TTM'] = data[-1]\n",
    "      for tbl in section.find_all('table',{'class':'ranges-table'}):\n",
    "        th = tbl.find('th').text\n",
    "        rows = tbl.find_all('td')\n",
    "        if th=='Compounded Sales Growth':\n",
    "          self.stock_to_data[self.stock]['Sales_Growth_10Y'] = rows[1].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Sales_Growth_5Y'] = rows[3].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Sales_Growth_3Y'] = rows[5].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Sales_Growth_TTM'] = rows[7].text.strip().replace('%','')\n",
    "        elif th=='Compounded Profit Growth':\n",
    "          self.stock_to_data[self.stock]['Profit_Growth_10Y'] = rows[1].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Profit_Growth_5Y'] = rows[3].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Profit_Growth_3Y'] = rows[5].text.strip().replace('%','')\n",
    "          self.stock_to_data[self.stock]['Profit_Growth_TTM'] = rows[7].text.strip().replace('%','')\n",
    "\n",
    "  def get_margin_data(self):\n",
    "    if self.stock_to_data[self.stock]['Sales_TTM'] not in [0,None]:\n",
    "      self.stock_to_data[self.stock]['NPM_TTM'] = round((self.stock_to_data[self.stock]['Profit_TTM']/self.stock_to_data[self.stock]['Sales_TTM']),2)*100\n",
    "\n",
    "  def get_fii_data(self):\n",
    "    section = self.stock_to_data[self.stock]['Soup'].find('section',{'id':'shareholding'})\n",
    "    if section:\n",
    "      tbl = section.find('table',{'class':'data-table'})\n",
    "      for row in tbl.find_all('tr'):\n",
    "        button = row.find('button')\n",
    "        if button:\n",
    "          txt = button['onclick'].strip()\n",
    "          type = txt[txt.find(\"('\")+2:txt.find(\"',\")]\n",
    "        else:\n",
    "          type = row.find('td').text.strip() if row.find('td') else None\n",
    "        data = [float(col.text.strip().replace(',','').replace('%',''))\n",
    "          for col in row.find_all('td')[1:] if col.text.strip()]\n",
    "        if type == 'foreign_institutions' and len(data)>7:\n",
    "          fii_ttm = round(sum(data[-4:])/4,2)\n",
    "          fii_pttm = round(sum(data[-8:-4])/4,2)\n",
    "          fii_ttm_pttm = fii_ttm-fii_pttm\n",
    "          self.stock_to_data[self.stock]['FII_TTM_PTTM'] = fii_ttm_pttm\n",
    "\n",
    "  def get_stock_to_data(self):\n",
    "    for i, (industry, url) in enumerate(self.industry_to_url.items(), start=1):\n",
    "      if i == 10:\n",
    "        break\n",
    "      time.sleep(1)\n",
    "      stocks_url = {ele.text : self.base_url+ele['href']\n",
    "        for ele in BeautifulSoup(requests.get(url).text,'html.parser').find_all('a', href=lambda href: href and href.startswith('/company/'))}\n",
    "      for s, (self.stock, stock_url) in enumerate(stocks_url.items(), start=1):\n",
    "        time.sleep(0.5)\n",
    "        soup = BeautifulSoup(requests.get(stock_url).text,'html.parser')\n",
    "        self.stock_to_data[self.stock] = {'url':stock_url,'Industry':industry,'Soup':soup, 'symbol':stock_url.split('/')[4],\n",
    "                                          'LTP':None,'52W L':None,'52W H':None,'PE':None,\n",
    "                                          'Reported_Upto':None,'Upcoming_Date':None,\n",
    "                                          'Sales_TTM':None,'Profit_TTM':None,'NPM_TTM':None,\n",
    "                                          'Sales_Growth_10Y':None,'Sales_Growth_5Y':None,'Sales_Growth_3Y':None,'Sales_Growth_TTM':None,\n",
    "                                          'Profit_Growth_10Y':None,'Profit_Growth_5Y':None,'Profit_Growth_3Y':None,'Profit_Growth_TTM':None,\n",
    "                                          'FII_TTM_PTTM':None}\n",
    "        print(f\"\\r{industry}[{i}/{len(self.industry_to_url)}] {self.stock}[{s}/{len(stocks_url)}] \", end=\"\", flush=True)\n",
    "        self.get_price_and_ratios()\n",
    "        self.get_quarterly_results()\n",
    "        self.get_profit_loss()\n",
    "        self.get_margin_data()\n",
    "        self.get_fii_data()\n",
    "        self.stock_to_data[self.stock]['Soup'] = None\n",
    "        if not self.stock_to_data[self.stock]['LTP']:\n",
    "          print(stock_url)\n",
    "\n",
    "scraper = Screener()\n",
    "scraper.get_industry_to_url()\n",
    "scraper.get_stock_to_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dca88b52-8611-4550-9a8f-9f2297bef56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Update Screener Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49e0748f-27da-4a34-bc24-c52fd42b1250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "doc = gc.open('Screener Tracker')\n",
    "stocks = doc.worksheet('Stocks')\n",
    "stocks.clear()\n",
    "stocks.clear_notes(['A','H','S'])\n",
    "stocks.clear_basic_filter()\n",
    "stocks_cells = []\n",
    "stocks_notes = {}\n",
    "stocks_cells.append(gspread.Cell(row=1,col=1,value='Stock'))\n",
    "timestamp = datetime.fromtimestamp(scraper.epoch_time,tz=pytz.timezone('Asia/Kolkata')).strftime('%Y-%m-%d %H:%M:%S')\n",
    "stocks_notes['A1'] = f'Timestamp : {timestamp}'\n",
    "stocks_notes['E1'] = '(LTP-52WL) X 100\\n--------------------------\\n(52WH-52WL)'\n",
    "headers = [\n",
    "    'Last\\nTraded\\nPrice',\n",
    "    '52\\nWeek\\nLow',\n",
    "    '52\\nWeek\\nHigh',\n",
    "    'Normal\\nScore',\n",
    "    'P/E',\n",
    "    'Sales\\nTTM\\n(Cr)',\n",
    "    'Profit\\nTTM\\n(Cr)',\n",
    "    'NPM\\nTTM\\n%',\n",
    "    'Sales\\nCAGR\\n10Y%',\n",
    "    'Sales\\nCAGR\\n5Y%',\n",
    "    'Sales\\nCAGR\\n3Y%',\n",
    "    'Sales\\nCAGR\\nTTM%',\n",
    "    'Profit\\nCAGR\\n10Y%',\n",
    "    'Profit\\nCAGR\\n5Y%',\n",
    "    'Profit\\nCAGR\\n3Y%',\n",
    "    'Profit\\nCAGR\\nTTM%',\n",
    "    'FIIs\\nChange\\nTTM',\n",
    "    'Reported Upto/\\nUpcoming Date',\n",
    "    'Industry'\n",
    "]\n",
    "for idx, h in enumerate(headers, 2):\n",
    "    stocks_cells.append(gspread.Cell(row=1, col=idx, value=h))\n",
    "\n",
    "row_num = 1\n",
    "for stock, data in scraper.stock_to_data.items():\n",
    "    row_num += 1\n",
    "    stocks_cells.append(gspread.Cell(row=row_num,col=1,value='=HYPERLINK(\"' + str(data['url']) + '\",\"' + str(data['symbol']) + '\")'))\n",
    "    stocks_notes[f'A{row_num}'] = stock\n",
    "    vals = [\n",
    "        str(data['LTP']),\n",
    "        int(data['52W L']),\n",
    "        int(data['52W H']),\n",
    "        round((data['LTP']-data['52W L'])/(data['52W H']-data['52W L']) if data.get('52W H') and (data['52W H']-data['52W L'])!=0 else 0,2)*100,\n",
    "        data['PE'],\n",
    "        data['Sales_TTM'],\n",
    "        data['Profit_TTM'],\n",
    "        data['NPM_TTM'],\n",
    "        data['Sales_Growth_10Y'],\n",
    "        data['Sales_Growth_5Y'],\n",
    "        data['Sales_Growth_3Y'],\n",
    "        data['Sales_Growth_TTM'],\n",
    "        data['Profit_Growth_10Y'],\n",
    "        data['Profit_Growth_5Y'],\n",
    "        data['Profit_Growth_3Y'],\n",
    "        data['Profit_Growth_TTM'],\n",
    "        data['FII_TTM_PTTM'],\n",
    "        data['Upcoming_Date'] if data['Upcoming_Date'] else data['Reported_Upto'],\n",
    "        data['Industry']\n",
    "    ]\n",
    "    \n",
    "    for i, val in enumerate(vals, 2):\n",
    "        stocks_cells.append(gspread.Cell(row=row_num, col=i, value=val))\n",
    "\n",
    "stocks.update_cells(stocks_cells, value_input_option='USER_ENTERED')\n",
    "stocks.update_notes(stocks_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2cac250-3423-4e6a-a77a-ff9eac7f2e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Update Zerodha Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8c9d530-9708-4402-a672-e51e6041bbea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "# 1. Resolve Folder IDs\n",
    "try:\n",
    "    ids = get_root_finance_structure()\n",
    "    print(f\"Found Folder IDs: {ids}\")\n",
    "except Exception as e:\n",
    "    print(f\"Stopped: {e}\")\n",
    "    ids = None\n",
    "\n",
    "if ids:\n",
    "    # --- Dividend Statement ---\n",
    "    dividend_statement = [['Symbol','Date','Net Amount','Year-Month']]\n",
    "    account = None\n",
    "    \n",
    "    # List files in Dividend folder\n",
    "    files = list_files_in_folder(ids['dividend'])\n",
    "    \n",
    "    for file in files:\n",
    "        if account is None and '-' in file['name']:\n",
    "            account = file['name'].split('-')[1] # Assuming format like 'Name-Account-...'\n",
    "            \n",
    "        print(f\"Processing Dividend: {file['name']}\")\n",
    "        \n",
    "        # Download file to memory\n",
    "        file_content = download_file_content(file['id'])\n",
    "        \n",
    "        # Open with openpyxl\n",
    "        workbook = load_workbook(file_content)\n",
    "        worksheet = workbook['Equity Dividends']\n",
    "        \n",
    "        found_header = False\n",
    "        for row in worksheet.iter_rows(values_only=True):\n",
    "            if not found_header:\n",
    "                if row and 'Symbol' in row: found_header = True\n",
    "                continue\n",
    "            if row[1] == 'Total Dividend Amount': break\n",
    "            \n",
    "            # Logic from original nb\n",
    "            date_val = row[3] # Ensure date format is handled if it comes as datetime object\n",
    "            if isinstance(date_val, datetime): date_val = date_val.strftime('%Y-%m-%d')\n",
    "                \n",
    "            dividend_statement.append([\n",
    "                str(row[1]).replace('#','').replace('6',''), # Symbol cleanup\n",
    "                date_val, \n",
    "                row[6], \n",
    "                str(date_val)[:7]\n",
    "            ])\n",
    "            \n",
    "    # Sort\n",
    "    dividend_statement[1:] = sorted(dividend_statement[1:], key=lambda row: datetime.strptime(row[1], \"%Y-%m-%d\"), reverse=True)\n",
    "\n",
    "    # --- Contract Notes ---\n",
    "    contract_note = [['Symbol','Date','Net Amount','Year-Month']]\n",
    "    files = list_files_in_folder(ids['contract'])\n",
    "    \n",
    "    for file in files:\n",
    "        # print(f\"Processing Contract: {file['name']}\")\n",
    "        file_content = download_file_content(file['id'])\n",
    "        workbook = load_workbook(file_content)\n",
    "        \n",
    "        for worksheet in workbook.worksheets:\n",
    "            header_found = False\n",
    "            skip_next_row = False\n",
    "            try:\n",
    "                sheet_date = datetime.strptime(worksheet.title, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "            except:\n",
    "                continue # Skip sheets that don't look like dates\n",
    "                \n",
    "            for row in worksheet.iter_rows(values_only=True):\n",
    "                if not header_found:\n",
    "                    if row and row[0] == 'Order No.':\n",
    "                        header_found = True\n",
    "                        skip_next_row = True\n",
    "                    continue\n",
    "                if skip_next_row:\n",
    "                    skip_next_row = False\n",
    "                    continue\n",
    "                if not row[0] or row[0] == 'PAY IN / PAY OUT OBLIGATION':\n",
    "                    break\n",
    "                \n",
    "                # Logic from original nb\n",
    "                symbol_raw = row[4].split(' - ')[0]\n",
    "                contract_note.append([\n",
    "                    symbol_raw, \n",
    "                    sheet_date,\n",
    "                    row[11] if row[5]=='buy' else row[12], \n",
    "                    sheet_date[:7]\n",
    "                ])\n",
    "                \n",
    "    contract_note[1:] = sorted(contract_note[1:], key=lambda row: datetime.strptime(row[1], \"%Y-%m-%d\"), reverse=True)\n",
    "\n",
    "    # --- Holdings CSV ---\n",
    "    holdings = [['Symbol','Quantity','Invested','Current']]\n",
    "    try:\n",
    "        holdings_file_id = get_file_id(ids['zerodha'], 'holdings.csv')\n",
    "        csv_content = download_file_content(holdings_file_id).read().decode('utf-8')\n",
    "        lines = csv_content.splitlines()\n",
    "        \n",
    "        for line in lines[1:]:\n",
    "            parts = line.strip().split(',')\n",
    "            if len(parts) > 5:\n",
    "                holdings.append([parts[0].replace('\"',''), parts[1], parts[4], parts[5]])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: holdings.csv not found or error reading: {e}\")\n",
    "\n",
    "    # --- Capital Gains Logic (Pure Python, mostly unchanged) ---\n",
    "    capital_gains = [['Symbol','Date','Invested','Unrealised','Realised','XIRR']]\n",
    "    symbol_to_contracts = {}\n",
    "    symbol_to_holdings = {}\n",
    "    \n",
    "    for contract in contract_note[1:]:\n",
    "      symbol = contract[0]\n",
    "      if symbol not in symbol_to_contracts: symbol_to_contracts[symbol] = []\n",
    "      symbol_to_contracts[symbol].append(contract)\n",
    "      \n",
    "    for holding in holdings[1:]:\n",
    "      symbol_to_holdings[holding[0]] = holding\n",
    "      \n",
    "    for symbol,contracts in symbol_to_contracts.items():\n",
    "      holdings_invested = 0.0\n",
    "      holdings_current = 0.0\n",
    "      contracts_invested_held = 0.0\n",
    "      contracts_invested_sold = 0.0\n",
    "      contracts_sold = 0.0\n",
    "      dates = []\n",
    "      flows = []\n",
    "      \n",
    "      if symbol in symbol_to_holdings:\n",
    "        holdings_invested = float(symbol_to_holdings[symbol][2])\n",
    "        holdings_current = float(symbol_to_holdings[symbol][3])\n",
    "        \n",
    "      for c in contracts:\n",
    "        amt = float(c[2])\n",
    "        d_obj = datetime.strptime(c[1], \"%Y-%m-%d\").date()\n",
    "        \n",
    "        if amt < 0: # Buy\n",
    "          if holdings_invested > contracts_invested_held:\n",
    "            contracts_invested_held += amt\n",
    "            unrealised = (abs(amt)/holdings_invested)*holdings_current if holdings_invested else 0\n",
    "            \n",
    "            try:\n",
    "                xirr_per = round(xirr([d_obj, datetime.today().date()], [amt, unrealised])*100, 2)\n",
    "            except: xirr_per = 0\n",
    "            \n",
    "            capital_gains.append([symbol, c[1], amt, unrealised+amt, 0, xirr_per])\n",
    "          else:\n",
    "            dates.append(d_obj)\n",
    "            flows.append(amt)\n",
    "            contracts_invested_sold += amt\n",
    "        else: # Sell\n",
    "          dates.append(d_obj)\n",
    "          flows.append(amt)\n",
    "          contracts_sold += amt\n",
    "          \n",
    "      if contracts_sold > 0:\n",
    "        realised = contracts_sold + contracts_invested_sold\n",
    "        try:\n",
    "            xirr_per = round(xirr(dates, flows)*100, 2)\n",
    "        except: xirr_per = 0\n",
    "        capital_gains.append([symbol, None, contracts_invested_sold, 0, realised, xirr_per])\n",
    "\n",
    "    # Final Write to Sheets\n",
    "    try:\n",
    "        doc = gc.open('Personal Finance')\n",
    "        sheet_to_data = {\n",
    "            'Dividend Statement': dividend_statement,\n",
    "            'Contract Note': contract_note,\n",
    "            'Holdings': holdings,\n",
    "            'Capital Gains': capital_gains\n",
    "        }\n",
    "        for sheet, data in sheet_to_data.items():\n",
    "            worksheet = doc.worksheet(sheet)\n",
    "            worksheet.clear()\n",
    "            worksheet.update('A1', data) # gspread update syntax\n",
    "        print(\"Personal Finance Sheet Updated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error updating Personal Finance sheet: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Screener_Zerodha",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
